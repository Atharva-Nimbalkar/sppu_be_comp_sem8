{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfDGCf5p5rC3",
        "outputId": "e35e1d6f-57d6-4cf2-f6e1-018784ee09d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  6 20:19:36 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the CUDA code to a .cu file\n",
        "\n",
        "%%writefile vector_add.cu\n",
        "\n",
        "// Filename: vector_add.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 1000000  // 1 million elements\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "__global__ void vectorAdd(int* a, int* b, int* c, int n) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Fill array with random integers\n",
        "void fillArray(int* arr, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        arr[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * sizeof(int);\n",
        "\n",
        "    // Allocate memory on host\n",
        "    int *h_a = (int*)malloc(size);\n",
        "    int *h_b = (int*)malloc(size);\n",
        "    int *h_c = (int*)malloc(size);\n",
        "\n",
        "    // Fill arrays with random data\n",
        "    fillArray(h_a, N);\n",
        "    fillArray(h_b, N);\n",
        "\n",
        "    // Allocate memory on device\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc((void**)&d_a, size);\n",
        "    cudaMalloc((void**)&d_b, size);\n",
        "    cudaMalloc((void**)&d_c, size);\n",
        "\n",
        "    // Copy input vectors to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "    // Wait for kernel to finish\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print first 10 results\n",
        "    printf(\"Vector Addition Result (first 10 elements):\\n\");\n",
        "    for (int i = 0; i < 10; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
        "    }\n",
        "\n",
        "    // Free memory - Frees both CPU and GPU memory.\n",
        "    free(h_a); free(h_b); free(h_c);\n",
        "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "216_aAnR6H_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ff6192-13d8-4de2-c130-35e1fe2ba150"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vector_add.cu -o vector_add\n",
        "\n"
      ],
      "metadata": {
        "id": "HvfnYBUe6L33"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add\n"
      ],
      "metadata": {
        "id": "Ua2MS2HZ7JTR",
        "outputId": "ef376090-09e1-415e-84f3-9b9e5262cd5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Addition Result (first 10 elements):\n",
            "83 + 89 = 172\n",
            "86 + 63 = 149\n",
            "77 + 84 = 161\n",
            "15 + 93 = 108\n",
            "93 + 81 = 174\n",
            "35 + 55 = 90\n",
            "86 + 6 = 92\n",
            "92 + 93 = 185\n",
            "49 + 61 = 110\n",
            "21 + 50 = 71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile matrix_mul.cu\n",
        "\n",
        "// %writefile matrix_mul.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define N 4  // You can increase this to 512 or 1024 for bigger matrices\n",
        "\n",
        "// CUDA kernel for Matrix Multiplication\n",
        "__global__ void matrixMulKernel(int* a, int* b, int* c, int width) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < width && col < width) {\n",
        "        int sum = 0;\n",
        "        for (int k = 0; k < width; ++k) {\n",
        "            sum += a[row * width + k] * b[k * width + col];\n",
        "        }\n",
        "        c[row * width + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Fill matrix with random integers\n",
        "void fillMatrix(int* mat, int width) {\n",
        "    for (int i = 0; i < width * width; i++) {\n",
        "        mat[i] = rand() % 10; // fill with random values 0-9\n",
        "    }\n",
        "}\n",
        "\n",
        "// Print matrix (for verification)\n",
        "void printMatrix(int* mat, int width) {\n",
        "    for (int i = 0; i < width; i++) {\n",
        "        for (int j = 0; j < width; j++) {\n",
        "            printf(\"%4d \", mat[i * width + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(int);\n",
        "\n",
        "    // Allocate memory on host\n",
        "    int *h_a = (int*)malloc(size);\n",
        "    int *h_b = (int*)malloc(size);\n",
        "    int *h_c = (int*)malloc(size);\n",
        "\n",
        "    // Fill host matrices with random values\n",
        "    fillMatrix(h_a, N);\n",
        "    fillMatrix(h_b, N);\n",
        "\n",
        "    // Allocate memory on device\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc((void**)&d_a, size);\n",
        "    cudaMalloc((void**)&d_b, size);\n",
        "    cudaMalloc((void**)&d_c, size);\n",
        "\n",
        "    // Copy host matrices to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 dimBlock(4, 4);\n",
        "    dim3 dimGrid((N + dimBlock.x - 1) / dimBlock.x,\n",
        "                 (N + dimBlock.y - 1) / dimBlock.y);\n",
        "\n",
        "    // Launch kernel\n",
        "    matrixMulKernel<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, N);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print results (for verification)\n",
        "    printf(\"Matrix A:\\n\"); printMatrix(h_a, N);\n",
        "    printf(\"Matrix B:\\n\"); printMatrix(h_b, N);\n",
        "    printf(\"Matrix C = A * B:\\n\"); printMatrix(h_c, N);\n",
        "\n",
        "    // Free memory\n",
        "    free(h_a); free(h_b); free(h_c);\n",
        "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G91D5z0n8Lm0",
        "outputId": "08eec9d8-b560-4afd-d81b-43d8bd97c6a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_mul.cu -o matrix_mul"
      ],
      "metadata": {
        "id": "5ydrCw-H8eqo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_mul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuSl0sf38e0x",
        "outputId": "b446ab36-dc17-4655-facb-d26c7ef511a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "   3    6    7    5 \n",
            "   3    5    6    2 \n",
            "   9    1    2    7 \n",
            "   0    9    3    6 \n",
            "\n",
            "Matrix B:\n",
            "   0    6    2    6 \n",
            "   1    8    7    9 \n",
            "   2    0    2    3 \n",
            "   7    5    9    2 \n",
            "\n",
            "Matrix C = A * B:\n",
            "  55   91  107  103 \n",
            "  31   68   71   85 \n",
            "  54   97   92   83 \n",
            "  57  102  123  102 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}